\chapter{Lexikalische Analyse}
Alles kontextfrei:
\begin{align*}
 N &\to ND\ |\ D \tag{für natürliche Zahlen}\\
 D &\to 0\ |\ ...\ |\ 9
\end{align*}

\begin{align*}
 I &\to IL'\ |\ L \tag{für Bezeichner}\\
 L &\to \texttt{'a'}\ |\ ...\ |\ \texttt{'b'}\\
 L' &\to L\ |\ D\ |\ \texttt{'\_'}
\end{align*}

\paragraph{1. Überlegung:} Konkrete Ausprägung ist unerheblich für Syntaxanalyse zusätzlicher Regeln: "Ballast". Außerdem verschärfter Ballast: \texttt{\dq\textvisiblespace\textvisiblespace  count\textvisiblespace +\textvisiblespace 94'\textbackslash n'\dq}
\paragraph{Einsicht:} Erledige Aufgaben wie Erkennung von Konstanten und Bezeichnern und Eliminierung von Leerzeichen in der ersten Phase: \emph{Lexer}
\paragraph{Lexer:} Quellprogramm $\to$ lexikalische Grundbausteine (\emph{"`Token"'})
\[<\textit{Tokenname},\text{\textit{optionales Attribut} (irrelevant für Syntaxanalyse)}>\]
\emph{Tokenname:} Sorte, Terminalsymbol der Syntaxanalyse.
\paragraph{Organisation:} Lexer als Prozedur, die bei Aufruf das nächste Token liefert.

\Bsp Bereinigte k. f. Grammatik am Beispiel arithmetischer Ausdrücke (integriert im Übersetzungsschema)
\newcommand{\print}[1]{\{\texttt{print('#1')}\}}
\newcommand{\printx}[1]{\{\texttt{print(}#1\texttt{)}\}}
\begin{center}
\begin{minipage}{0.7\linewidth}
\begin{align*}
 E &\to E + T\print{+}\ |\ E - T\print{-}\ |\ T \\
 T &\to T * F\print{*}\ |\ T / F\print{/}\ |\ F \\
 F &\to (E)\ |\ \rnode{Tokenname_n}{n}\printx{n.\rnode{attr_value}{v}}\ |\ \rnode{Tokenname_i}{i}\printx{n.\rnode{attr_id}{l}}
\end{align*}
{\footnotesize \rnode{Tn_start}{Tokenname $n$: Number} \hfill \rnode{av_start}{Attributwert} \hfill \rnode{Ti_start}{Tokenname $i$: Identifier} \hfill \rnode{ai_start}{Attribut $l$ für \emph{Lexem}}}
\ncline{->}{Tn_start}{Tokenname_n}\ncline{->}{av_start}{attr_value}\ncline{->}{Ti_start}{Tokenname_i}\ncline{->}{ai_start}{attr_id}
\end{minipage}
\vline\hfill
\begin{minipage}{0.25\linewidth}
 kontextfreie Grammatik für Syntaxanalyse
\end{minipage}
\end{center}
\paragraph{Heute:} \emph{Einfacher Lexer} per Hand programmieren.
\paragraph{Später:} Endliche Automaten zur Erkennung regulärer Strukturen. (Automatisch mit Tools \emph{Lex})

\paragraph{1. Teilaufgabe:} Entferne von Leerzeichen\\
peek sei Zeiger auf jeweils nächsten Character der Eingabe.

\begin{lstlisting}[language=Java]
// Kompletter Code im Drachenbuch
for(;; peek = next input character) {
    if (peek == ' ' || peek == '\t') continue;
    else if (peek == '\n') line = line + 1;
    else break;
}
\end{lstlisting}

\paragraph{2. Teilaufgabe:} Erkenne Konstanten\\
Hier: natürliche Zahlen
\begin{lstlisting}[language=Java,mathescape=True]
if (isDigit(peek)) {
    v = 0;
    do {
        v = v * 10 + integer value of peek;
        peek = next input character
    } while (isDigit(peek));
    return token <$n$, v>
}
\end{lstlisting}

\paragraph{3. Teilaufgabe:} Erkenne Schlüsselwörter ("`reservieter Wörter"') und Bezeichner
\begin{center}
\texttt{\dq\textvisiblespace\textvisiblespace\textvisiblespace  $\underbrace{\texttt{count}}_{\text{Lexem = "`\texttt{count}"'}}$\textvisiblespace\textvisiblespace=\textvisiblespace $\underbrace{\texttt{count}}$\textvisiblespace +\textvisiblespace 94'\textbackslash n'\dq}
\end{center}
\paragraph{Idee:} Symboltabelle (Hashtabelle mit Schlüsseln (Wörtern)). Initialisiere mit Schlüsselwörtern!
\begin{lstlisting}[language=Java,mathescape=True]
Hashtabelle words = new Hashtabelle();  // Symboltabelle initialisierre mit Schluesselwoertern
if (isLetter(peek)) {
    collect letters or digits in Buffer b;
    s = strung contained in b;
    w = token returned by words.get(s);
    if ( w ist not null ) return w;
    else {
        enter the key-value-pair (s, <$i$, s>) into words;
        return token <$i$, s>;
    }
}
\end{lstlisting}
\begin{lstlisting}
Token scan() {
    // 1. Leerzeichen
        ...
    // 2. Erkenne Konstanten
        ...
    // 3. Erkenne Bezeichner und Schluesselwoerter
        ...
    t = new Token(peek);
    peek = next input character
    return t;
}
\end{lstlisting}
